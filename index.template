<!DOCTYPE HTML>
<!--
  Based on
	Spatial by TEMPLATED
	templated.co @templatedco
	Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
	<head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117339330-4"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-117339330-4');
    </script>

    <title>
      Net2Net
    </title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="landing">

		<!-- Banner -->
			<section id="banner">
        <h2>
          Network-to-Network Translation with <br/>Conditional Invertible Neural
          Networks
        </h2>
        <p>
        <a href="https://github.com/rromb">Robin Rombach</a>&ast;,
        <a href="https://github.com/pesser">Patrick Esser</a>&ast;, 
        <a href="https://hci.iwr.uni-heidelberg.de/Staff/bommer">Bj&ouml;rn Ommer</a><br/>
        <a href="https://www.iwr.uni-heidelberg.de/">IWR, Heidelberg University</a><br/>
        <a href="https://neurips.cc/Conferences/2020">NeurIPS 2020 (Oral)</a>
        </p>
			</section>

			<!-- One -->
				<section id="one" class="wrapper style1">
					<div class="container 75%">
						<div class="row 200%">
							<div class="6u 12u$(medium) vert-center" style="margin:1% 0">
                  <div class="container 25%">

                    <div class="image fit captioned align-left"
                                style="margin-bottom:2em; box-shadow:0 0;
                                text-align:justify">
                      <img src="paper/teaser.png" alt="" style="border:0px solid black"/>
                      <strong>TL;DR:</strong> Our approach distills the residual information of one
                      model with respect to another's and thereby enables
                      translation between fixed off-the-shelve expert models
                      such as BERT and BigGAN without having to modify or
                      finetune them.
                    </div>

                    <div class="image fit captioned align-center"
                                style="margin-bottom:0em; box-shadow:0 0">
                      <a href="paper/paper.pdf">
                        <img src="paper/paper.jpg" alt="" style="border:1px solid black"/>
                      </a>
                      <!--
                      <a href="https://arxiv.org/">arXiv</a>
                      <div class="headerDivider"></div>
                      --!>
                      <a href="paper/paper.bib">BibTeX</a>
                      <div class="headerDivider"></div>
                      <a href="https://github.com/CompVis/net2net">GitHub</a>
                      <br/>
                      &ast; equal contribution
                    </div>

                  </div>
							</div>
							<div class="6u$ 12u$(medium)">
                <h1>Abstract</h1>
                <p style="text-align: justify">
Given the ever-increasing computational costs of modern machine learning
models, we need to find new ways to reuse such expert models and thus tap
into the resources that have been invested in their creation. Recent work
suggests that the power of these massive models is captured by the
representations they learn. Therefore, we seek a model that can relate
between different existing representations and propose to solve this task
with a conditionally invertible network. This network demonstrates its
capability by (i) providing generic transfer between diverse domains, (ii)
enabling controlled content synthesis by allowing modification in other
domains, and (iii) facilitating diagnosis of existing representations by
translating them into interpretable domains such as images. Our domain
transfer network can translate between fixed representations without having
to learn or finetune them. This allows users to utilize various existing
domain-specific expert models from the literature that had been trained with
extensive computational resources.  Experiments on diverse conditional image
synthesis tasks, competitive image modification results and experiments on
image-to-image and text-to-image generation demonstrate the generic
applicability of our approach. For example, we translate between BERT and
BigGAN, state-of-the-art text and image models to provide text-to-image
generation, which neither of both experts can perform on their own.
                </p>
							</div>
						</div>
            <!--
          <p style="text-align:center">Related work <br/><a
             href="https://compvis.github.io/iin/">"A Disentangling
             Invertible Interpretation Network for Explaining Latent
           Representations"</a></p>
					</div>
            -->
				</section>

			<!-- Two -->
				<section id="two" class="wrapper style2 special">
					<div class="container">
						<header class="major">
							<h2>Results</h2>
							<p>and applications of our model.</p>
						</header>

            __TEMPLATE_STRING__

				  </div>
				</section>


			<!-- Four -->
				<section id="four" class="wrapper style3 special">
					<div class="container">
						<header class="major">
							<h2>Acknowledgement</h2>
              <p>
              This page is based on a design by <a href="http://templated.co">TEMPLATED</a>.
  This work has been supported in part by the German Research Foundation (DFG)
  projects 371923335, 421703927, and EXC 2181/1 - 390900948, the German federal
  ministry BMWi within the project KI Absicherung and a hardware donation
  from NVIDIA Corporation.
              </p>
						</header>
					</div>
				</section>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
